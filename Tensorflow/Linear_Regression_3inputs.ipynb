{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-variable Linear_Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INPUT : 2 ( X1, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 학습코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run_count : [0010], Train_cost =[0.4722], W1 =[0.7359], W2 =[0.3855], W3 =[0.3855], b =[0.2986], pred =[0.9926 1.7753 2.4025 3.2630 3.8125]\n",
      "Run_count : [0020], Train_cost =[0.0357], W1 =[0.8757], W2 =[0.4392], W3 =[0.4392], b =[0.3392], pred =[1.2078 2.0873 2.9471 3.8364 4.6864]\n",
      "Run_count : [0030], Train_cost =[0.0210], W1 =[0.9046], W2 =[0.4474], W3 =[0.4474], b =[0.3370], pred =[1.2409 2.1259 3.0473 3.9140 4.8537]\n",
      "Run_count : [0040], Train_cost =[0.0193], W1 =[0.9124], W2 =[0.4497], W3 =[0.4497], b =[0.3279], pred =[1.2408 2.1271 3.0646 3.9253 4.8885]\n",
      "Run_count : [0050], Train_cost =[0.0181], W1 =[0.9161], W2 =[0.4513], W3 =[0.4513], b =[0.3179], pred =[1.2347 2.1237 3.0663 3.9285 4.8978]\n",
      "Run_count : [0060], Train_cost =[0.0169], W1 =[0.9189], W2 =[0.4529], W3 =[0.4529], b =[0.3080], pred =[1.2276 2.1198 3.0649 3.9307 4.9022]\n",
      "Run_count : [0070], Train_cost =[0.0159], W1 =[0.9215], W2 =[0.4543], W3 =[0.4543], b =[0.2983], pred =[1.2205 2.1161 3.0630 3.9329 4.9055]\n",
      "Run_count : [0080], Train_cost =[0.0149], W1 =[0.9240], W2 =[0.4558], W3 =[0.4558], b =[0.2890], pred =[1.2136 2.1124 3.0611 3.9350 4.9085]\n",
      "Run_count : [0090], Train_cost =[0.0140], W1 =[0.9263], W2 =[0.4572], W3 =[0.4572], b =[0.2799], pred =[1.2069 2.1089 3.0591 3.9370 4.9114]\n",
      "Run_count : [0100], Train_cost =[0.0131], W1 =[0.9287], W2 =[0.4585], W3 =[0.4585], b =[0.2711], pred =[1.2004 2.1055 3.0573 3.9390 4.9142]\n",
      "Optimization Finished!\n",
      "Run_count : [0100], Train_cost =[0.0131], W1 =[0.9287], W2 =[0.4585], W3 =[0.4585], b =[0.2711], pred =[1.2004 2.1055 3.0573 3.9390 4.9142]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_cnt = 100\n",
    "display_step = 10\n",
    "\n",
    "train_X1 = np.array([1., 0., 3., 0., 5.])\n",
    "train_X2 = np.array([0., 2., 0., 4., 0.])\n",
    "train_X3 = np.array([0., 2., 0., 4., 0.])\n",
    "\n",
    "train_Y = np.array([1., 2., 3., 4., 5.])\n",
    "\n",
    "X1 = tf.placeholder(\"float\")\n",
    "X2 = tf.placeholder(\"float\")\n",
    "X3 = tf.placeholder(\"float\")\n",
    "\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "W1 = tf.Variable([.0], tf.float32, name = \"weight1\")\n",
    "W2 = tf.Variable([.0], tf.float32, name = \"weight2\")\n",
    "W3 = tf.Variable([.0], tf.float32, name = \"weight3\")\n",
    "\n",
    "b = tf.Variable([.0], tf.float32, name = \"bias\")\n",
    "\n",
    "pred = X1 * W1 + X2 * W2 + X3 * W3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.pow(pred-Y, 2))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "op_train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(training_cnt):\n",
    "    r_cost, r_W1, r_W2, r_W3, r_b, r_pred, _ = sess.run([cost, W1, W2, W3, b, pred, op_train], feed_dict = {X1: train_X1, X2: train_X2, X3: train_X3, Y: train_Y})\n",
    "    #print(r_pred)\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], W3 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W1, r_W2, r_W3, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))\n",
    "                  \n",
    "print(\"Optimization Finished!\") \n",
    "print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], W3 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W1, r_W2, r_W3, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 모델 구축(build graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_cnt = 10\n",
    "display_step = 1\n",
    "\n",
    "train_X1 = np.array([1., 0., 3., 0., 5.])\n",
    "train_X2 = np.array([0., 2., 0., 4., 0.])\n",
    "\n",
    "train_Y = np.array([1., 2., 3., 4., 5.])\n",
    "\n",
    "X1 = tf.placeholder(\"float\")\n",
    "X2 = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "W1 = tf.Variable([.0], tf.float32, name = \"weight1\")\n",
    "W2 = tf.Variable([.0], tf.float32, name = \"weight2\")\n",
    "b = tf.Variable([.0], tf.float32, name = \"bias\")\n",
    "\n",
    "pred = X1 * W1 + X2 * W2 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.pow(pred-Y, 2))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "op_train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 모델 실행 (run/update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(training_cnt):\n",
    "    r_cost, r_W1, r_W2, r_b,r_pred, _ = sess.run([cost, W1, W2, b,pred, op_train], feed_dict = {X1: train_X1, X2: train_X2, Y: train_Y})\n",
    "\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W1, r_W2, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))\n",
    "                  \n",
    "print(\"Optimization Finished!\") \n",
    "print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W1, r_W2, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 모델 구축(build graph)\n",
    "#### 트레이닝 데이터 변수 선언\n",
    "- 입력으로 들어가는 x1, x2 즉 두개의 변수 선언\n",
    "- 출력은 하나 Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1 = np.array([1., 0., 3., 0., 5.])\n",
    "train_X2 = np.array([0., 2., 0., 4., 0.])\n",
    "\n",
    "train_Y = np.array([1., 2., 3., 4., 5.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf graph input\n",
    "- linear_regression model과 같다. 단지 입력변수를 담는 placeholter가 2개로 늘어났다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = tf.placeholder(\"float\")\n",
    "X2 = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set model weight\n",
    "- 입력변수가 2개이기 때문에 weight도 2개로 늘어난다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable([.0], tf.float32, name = \"weight1\")\n",
    "W2 = tf.Variable([.0], tf.float32, name = \"weight2\")\n",
    "b = tf.Variable([.0], tf.float32, name = \"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear model(예측 값 구현)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(x_1,x_2)=x_1w_1+x_2w_2+b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = X1 * W1 + X2 * W2 + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cost/loss function 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$cost(W,b)=\\frac 1m\\sum_{i=1}^m(H(x_1^{(i)},x_2^{(i)})-y^{(i)})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.pow(pred-Y, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 --> cost 최소화\n",
    "- gradientdecent 함수 사용(경사 하강법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.pow(pred-Y, 2))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate) # 하이퍼파라미터에서 설정한 값\n",
    "op_train = optimizer.minimize(cost) # optimizer에서 나온값을 최소하 시키도록 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 모델 실행 (run/update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션오픈\n",
    "sess = tf.Session()\n",
    "# 변수들에 초기값 할당\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_cnt): # traing_cnt 횟수만큼 반복 실행\n",
    "    r_cost, r_W1, r_W2, r_b,r_pred, _ = sess.run([cost, W1, W2, b,pred, op_train], feed_dict = {X1: train_X1, X2: train_X2, Y: train_Y})\n",
    "    #sess.run을통해 학습한(변경된) cost, W, b 값을 r_cost, r_W, r_b 에 update\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W1, r_W2, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))\n",
    "        # sess.run을 통해 학습된 값 출력(pred의 경우 value가 5개가 나오기 때문에 그 값을 소수점4번째까지만 나타내려 각각 print함 )\n",
    "        \n",
    "print(\"Optimization Finished!\") \n",
    "print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W1, r_W2, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)  def(함수 만들기)\n",
    "- build graph, run graph 함수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_cnt = 10\n",
    "display_step = 1\n",
    "\n",
    "train_X1 = np.array([1., 0., 3., 0., 5.])\n",
    "train_X2 = np.array([0., 2., 0., 4., 0.])\n",
    "\n",
    "train_Y = np.array([1., 2., 3., 4., 5.])\n",
    "\n",
    "def make_graph() :\n",
    "    global X1, X2, Y, W1, W2, b, pred ,cost,optimizer, op_train\n",
    "\n",
    "    X1 = tf.placeholder(\"float\")\n",
    "    X2 = tf.placeholder(\"float\")\n",
    "    Y = tf.placeholder(\"float\")\n",
    "\n",
    "    W1 = tf.Variable([.0], tf.float32, name = \"weight1\")\n",
    "    W2 = tf.Variable([.0], tf.float32, name = \"weight2\")\n",
    "    b = tf.Variable([.0], tf.float32, name = \"bias\")\n",
    "\n",
    "    pred = X1 * W1 + X2 * W2 + b\n",
    "\n",
    "    cost = tf.reduce_mean(tf.pow(pred-Y, 2))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    op_train = optimizer.minimize(cost)\n",
    "\n",
    "def run_graph() :    \n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(training_cnt):\n",
    "        r_cost, r_W1, r_W2, r_b,r_pred, _ = sess.run([cost, W1, W2, b,pred, op_train], feed_dict = {X1: train_X1, X2: train_X2, Y: train_Y})\n",
    "\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "                  % (epoch+1, r_cost, r_W1, r_W2, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))\n",
    "                  \n",
    "    print(\"Optimization Finished!\") \n",
    "    print(\"Run_count : [%04d], Train_cost =[%.4f], W1 =[%.4f], W2 =[%.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W1, r_W2, r_b,r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. INPUT : 2 ( matrix 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_cnt = 10\n",
    "display_step = 1\n",
    "\n",
    "train_MX = np.array([[1., 0.], [0., 2.], [3., 0.], [0., 4.], [5., 0.] ])\n",
    "train_Y = np.array([[1.], [2.], [3.], [4.], [5.]])\n",
    "\n",
    "MX = tf.placeholder(\"float\",shape=[None, 2])\n",
    "Y = tf.placeholder(\"float\", shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.zeros([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')\n",
    "\n",
    "pred = tf.matmul(MX ,W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.pow(pred-Y, 2))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "op_train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(training_cnt):\n",
    "    r_cost, r_W, r_b, r_pred, _ = sess.run([cost, W, b, pred, op_train], feed_dict = {MX: train_MX, Y: train_Y})\n",
    "    \n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Run_count : [%04d], Train_cost =[%.4f], W =[%.4f %.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W[0], r_W[1], r_b, r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))\n",
    "        \n",
    "                   \n",
    "print(\"Optimization Finished!\") \n",
    "print(\"Run_count : [%04d], Train_cost =[%.4f], W =[%.4f %.4f], b =[%.4f], pred =[%.4f %.4f %.4f %.4f %.4f]\" \n",
    "              % (epoch+1, r_cost, r_W[0], r_W[1], r_b, r_pred[0],r_pred[1],r_pred[2],r_pred[3],r_pred[4] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matrix를 이용한 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$H(x_1,x_2)=x_1w_1+x_2w_2+b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$( x_1 \\  \\ x_2) * {w_1 \\choose w_2} = ( x_1w_1 + x_2w_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MX = np.array([[1., 0.], [0., 2.], [3., 0.], [0., 4.], [5., 0.] ])\n",
    "  # 5 by 2 matrix\n",
    "train_Y = np.array([[1.], [2.], [3.], [4.], [5.]])\n",
    "  # 5 by 1 matrix\n",
    "MX = tf.placeholder(\"float\",shape=[None, 2])  #들어오는 row는 정해진게 없고, column 은 2개 즉 변수 2개\n",
    "Y = tf.placeholder(\"float\", shape=[None, 1])  \n",
    "\n",
    "W = tf.Variable(tf.zeros([2, 1]), name='weight')  #MX의 두개의 변수와 연결이 되기때문에 row는 2개 출력 값은 Y와 같은 shape여야 하므로 하나\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')\n",
    "\n",
    "pred = tf.matmul(MX ,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "0804"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
